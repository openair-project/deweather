% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/build_dw_model.R
\name{build_dw_model}
\alias{build_dw_model}
\title{Build a Deweather Model}
\usage{
build_dw_model(
  data,
  pollutant,
  vars = c("trend", "ws", "wd", "hour", "weekday", "air_temp"),
  tree_depth = 5,
  trees = 50L,
  learn_rate = 0.1,
  mtry = NULL,
  min_n = 10L,
  loss_reduction = 0,
  sample_size = 1L,
  stop_iter = 45L,
  engine = c("xgboost", "lightgbm", "ranger"),
  ...,
  .date = "date"
)
}
\arguments{
\item{data}{An input \code{data.frame} containing one pollutant column (defined
using \code{pollutant}) and a collection of feature columns (defined using
\code{vars}).}

\item{pollutant}{The name of the column (likely a pollutant) in \code{data} to
predict.}

\item{vars}{The name of the columns in \code{data} to use as model features -
i.e., to predict the values in the \code{pollutant} column. Any character
columns will be coerced to factors. \code{"hour"}, \code{"weekday"}, \code{"trend"},
\code{"yday"}, \code{"week"}, and \code{"month"} are special terms and will be passed to
\code{\link[=append_dw_vars]{append_dw_vars()}} if not present in \code{names(data)}.}

\item{tree_depth}{Tree Depth \verb{<xgboost|lightgbm>}

An integer for the maximum depth of the tree (i.e., number of splits).}

\item{trees}{Number of Trees \verb{<xgboost|lightgbm|ranger>}

An integer for the number of trees contained in the ensemble.}

\item{learn_rate}{Learning Rate \verb{<xgboost|lightgbm>}

A number for the rate at which the boosting algorithm adapts from
iteration-to-iteration. This is sometimes referred to as the shrinkage
parameter.}

\item{mtry}{Number of Randomly Selected Predictors
\verb{<xgboost|lightgbm|ranger>}

A number for the number (or proportion) of predictors that will be randomly
sampled at each split when creating the tree models.}

\item{min_n}{Minimal Node Size \verb{<xgboost|lightgbm|ranger>}

An integer for the minimum number of data points in a node that is required
for the node to be split further.}

\item{loss_reduction}{Minimum Loss Reduction \verb{<xgboost|lightgbm>}

A number for the reduction in the loss function required to split further.}

\item{sample_size}{Proportion Observations Sampled \verb{<xgboost>}

A number for the number (or proportion) of data that is exposed to the
fitting routine.}

\item{stop_iter}{Number of Iterations Before Stopping \verb{<xgboost>}

The number of iterations without improvement before stopping.}

\item{engine}{A single character string specifying what computational engine
to use for fitting. Can be \code{"xgboost"}, \code{"lightgbm"} (boosted trees) or
\code{"ranger"} (random forest). See the documentation below for more
information.}

\item{...}{Not current used.}

\item{.date}{The name of the 'date' column which defines the air quality
timeseries. Passed to \code{\link[=append_dw_vars]{append_dw_vars()}} if needed. Also used to extract
the time zone of the data for later restoration if \code{trend} is used as a
variable.}
}
\value{
a 'Deweather' object for further analysis
}
\description{
This function builds a 'deweathering' machine learning model with useful
methods for interrogating it in an air quality and meteorological context. It
uses any number of variables (most usefully meteorological variables like
wind speed and wind direction and temporal variables defined in
\code{\link[=append_dw_vars]{append_dw_vars()}}) to fit a model predicting a given \code{pollutant}. While
these models are useful for 'removing' the effects of meteorology from an air
quality time series (e.g., through \code{\link[=simulate_dw_met]{simulate_dw_met()}}), they are also useful
for explanatory analysis (e.g., through \code{\link[=plot_dw_partial_1d]{plot_dw_partial_1d()}}).
}
\section{Modelling Approaches and Parameters}{

\subsection{Types of Model}{

There are two modelling approaches available to \code{\link[=build_dw_model]{build_dw_model()}}:
\itemize{
\item Boosted Trees (\code{xgboost}, \code{lightgbm})
\item Random Forest (\code{ranger})
}

Each of these approaches take different parameters.
}

\subsection{Boosted Trees}{

Two engines are available for boosted tree models:
\itemize{
\item \code{"xgboost"}
\item \code{"lightgbm"}
}

The following parameters apply:
\itemize{
\item \code{tree_depth}: Tree Depth
\item \code{trees}: # Trees
\item \code{learn_rate}: Learning Rate
\item \code{mtry}: # Randomly Selected Predictors
\item \code{min_n}: Minimal Node Size
\item \code{loss_reduction}: Minimum Loss Reduction
\item \code{sample_size}: Proportion Observations Sampled (\code{xgboost} only)
\item \code{stop_iter}: # Iterations Before Stopping (\code{xgboost} only)
}
}

\subsection{Random Forest}{

One engine is available for random forest models:
\itemize{
\item \code{"ranger"}
}

The following parameters apply:
\itemize{
\item \code{mtry}: # Randomly Selected Predictors
\item \code{trees}: # Trees
\item \code{min_n}: Minimal Node Size
}
}
}

