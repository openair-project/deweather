% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune_dw_model.R
\name{tune_dw_model}
\alias{tune_dw_model}
\title{Tune a deweather model}
\usage{
tune_dw_model(
  data,
  pollutant,
  vars = c("trend", "ws", "wd", "hour", "weekday", "air_temp"),
  tree_depth = 5,
  trees = 50L,
  learn_rate = 0.1,
  mtry = NULL,
  min_n = 10L,
  loss_reduction = 0,
  sample_size = 1L,
  stop_iter = 45L,
  engine = c("xgboost", "lightgbm", "ranger"),
  split_prop = 3/4,
  grid_levels = 5,
  v_partitions = 10,
  progress = TRUE,
  ...,
  .date = "date"
)
}
\arguments{
\item{data}{An input \code{data.frame} containing one pollutant column (defined
using \code{pollutant}) and a collection of feature columns (defined using
\code{vars}).}

\item{pollutant}{The name of the column (likely a pollutant) in \code{data} to
predict.}

\item{vars}{The name of the columns in \code{data} to use as model features -
i.e., to predict the values in the \code{pollutant} column. Any character
columns will be coerced to factors. \code{"hour"}, \code{"weekday"}, \code{"trend"},
\code{"yday"}, \code{"week"}, and \code{"month"} are special terms and will be passed to
\code{\link[=append_dw_vars]{append_dw_vars()}} if not present in \code{names(data)}.}

\item{tree_depth, trees, learn_rate, mtry, min_n, loss_reduction, sample_size, stop_iter}{If length 1, these parameters will be fixed. If length \code{2}, the parameter
will be tuned within the range defined between the first and last value. For
example, if \code{tree_depth = c(1, 5)} and \code{grid_levels = 3}, tree depths of \code{1},
\code{3}, and \code{5} will be tested. See \code{\link[=build_dw_model]{build_dw_model()}} for specific parameter
definitions.}

\item{engine}{A single character string specifying what computational engine
to use for fitting. Can be \code{"xgboost"}, \code{"lightgbm"} (boosted trees) or
\code{"ranger"} (random forest). See the documentation below for more
information.}

\item{split_prop}{The proportion of data to be retained for
modeling/analysis. Passed to the \code{prop} argument of
\code{\link[rsample:initial_split]{rsample::initial_split()}}.}

\item{grid_levels}{An integer for the number of values of each parameter to
use to make the regular grid. Passed to the \code{levels} argument of
\code{\link[dials:grid_regular]{dials::grid_regular()}}.}

\item{v_partitions}{The number of partitions of the data set to use for
v-fold cross-validation. Passed to the \code{v} argument of
\code{\link[rsample:vfold_cv]{rsample::vfold_cv()}}.}

\item{progress}{Log progress in the console? Passed to the \code{verbose} argument
of \code{\link[tune:control_grid]{tune::control_grid()}}. Note that logging does not occur when parallel
processing is used.}

\item{...}{Used to pass additional engine-specific parameters to the model.
The parameters listed here can be tuned using \code{\link[=tune_dw_model]{tune_dw_model()}}. All other
parameters must be fixed.
\itemize{
\item \code{alpha}: \verb{<xgboost>} L1 regularization term on weights.
\item \code{lambda}: \verb{<xgboost>} L2 regularization term on weights.
\item \code{num_leaves}: \verb{<lightgbm>} max number of leaves in one tree.
\item \code{regularization.factor}: \verb{<ranger>} Regularization factor (gain penalization).
\item \code{regularization.usedepth}: \verb{<ranger>} Consider the depth in regularization? (\code{TRUE}/\code{FALSE}).
\item \code{splitrule}: \verb{<ranger>} Splitting rule. One of \link[dials:ranger_parameters]{dials::ranger_reg_rules}.
\item \code{alpha}: \verb{<ranger>} Significance threshold to allow splitting (for \code{splitrule = "maxstat"}).
\item \code{minprop}: \verb{<ranger>} Lower quantile of covariate distribution to be considered for splitting (for \code{splitrule = "maxstat"}).
\item \code{num.random.splits}: \verb{<ranger>} Number of random splits to consider for each candidate splitting variable (for \code{splitrule = "extratrees"}).
}}

\item{.date}{The name of the 'date' column which defines the air quality
timeseries. Passed to \code{\link[=append_dw_vars]{append_dw_vars()}} if needed. Also used to extract
the time zone of the data for later restoration if \code{trend} is used as a
variable.}
}
\description{
This function performs hyperparameter tuning for a gradient boosting model
used in deweathering air pollution data. It uses cross-validation to find
optimal hyperparameters and returns the best performing model along with
performance metrics and visualizations. Parallel processing (e.g., through
the \code{mirai} package) is recommended to speed up tuning - see
\url{https://tune.tidymodels.org/articles/extras/optimizations.html#parallel-processing}.
}
\details{
The function performs the following steps:
\itemize{
\item Removes rows with missing values in the pollutant or predictor variables
\item Splits data into training and testing sets
\item Creates a tuning grid for any parameters specified as ranges
\item Performs grid search with cross-validation to find optimal hyperparameters
\item Fits a final model using the best hyperparameters
\item Generates predictions and performance metrics
}

At least one hyperparameter must be specified as a range (vector of length
2) for tuning to occur. Single values are treated as fixed parameters.
}
\section{Modelling Approaches and Parameters}{

\subsection{Types of Model}{

There are two modelling approaches available to \code{\link[=build_dw_model]{build_dw_model()}}:
\itemize{
\item Boosted Trees (\code{xgboost}, \code{lightgbm})
\item Random Forest (\code{ranger})
}

Each of these approaches take different parameters.
}

\subsection{Boosted Trees}{

Two engines are available for boosted tree models:
\itemize{
\item \code{"xgboost"}
\item \code{"lightgbm"}
}

The following universal parameters apply and are tunable:
\itemize{
\item \code{tree_depth}: Tree Depth
\item \code{trees}: # Trees
\item \code{learn_rate}: Learning Rate
\item \code{mtry}: # Randomly Selected Predictors
\item \code{min_n}: Minimal Node Size
\item \code{loss_reduction}: Minimum Loss Reduction
\item \code{sample_size}: Proportion Observations Sampled (\code{xgboost} only)
\item \code{stop_iter}: # Iterations Before Stopping (\code{xgboost} only)
}

The following \code{xgboost}-specific parameters are tunable:
\itemize{
\item \code{alpha}: L1 regularization term on weights. Increasing this value will make model more conservative
\item \code{lambda}: L2 regularization term on weights. Increasing this value will make model more conservative
}

The following \code{lightgbm}-specific parameters are tunable:
\itemize{
\item \code{num_leaves}: max number of leaves in one tree
}
}

\subsection{Random Forest}{

One engine is available for random forest models:
\itemize{
\item \code{"ranger"}
}

The following universal parameters apply and are tunable:
\itemize{
\item \code{mtry}: # Randomly Selected Predictors
\item \code{trees}: # Trees
\item \code{min_n}: Minimal Node Size
}

The following \code{ranger}-specific parameters are tunable:
\itemize{
\item \code{regularization.factor}: Regularization factor (gain penalization)
\item \code{regularization.usedepth}: Consider the depth in regularization? (\code{TRUE}/\code{FALSE})
\item \code{splitrule}: Splitting rule. One of \link[dials:ranger_parameters]{dials::ranger_reg_rules}
\item \code{alpha}: Significance threshold to allow splitting (for \code{splitrule = "maxstat"})
\item \code{minprop}: Lower quantile of covariate distribution to be considered for splitting (for \code{splitrule = "maxstat"})
\item \code{num.random.splits}: Number of random splits to consider for each candidate splitting variable (for \code{splitrule = "extratrees"})
}
}
}

\seealso{
Other Model Tuning Functions: 
\code{\link{plot_tdw_testing_scatter}()},
\code{\link{plot_tdw_tuning_metrics}()}
}
\author{
Jack Davison
}
\concept{Model Tuning Functions}
